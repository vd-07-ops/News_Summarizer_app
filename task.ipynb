{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e9476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vedant Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vedant Dave\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://4aee745afe6e753909.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prevent Transformers from trying to import TensorFlow or Flax\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"USE_TF\"] = \"0\"\n",
    "os.environ[\"USE_FLAX\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import gradio as gr\n",
    "from datasets import load_dataset\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# BART large fine-tuned on XSum is optimized for extreme abstractive summarization of news articles,\n",
    "# making it suitable for generating short, focused summaries from long inputs.\n",
    "MODEL_NAME = \"facebook/bart-large-xsum\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BartForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def prepare_sample_data():\n",
    "    dataset = load_dataset(\"xsum\", split=\"train\", streaming=True)\n",
    "    it = iter(dataset)\n",
    "    return [next(it)[\"document\"] for _ in range(2)]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def summarize_news(text: str):\n",
    "    if not text or len(text.strip()) < 50:\n",
    "        return \"Error: Please provide a longer article (at least 50 characters).\"\n",
    "\n",
    "    try:\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=1024\n",
    "        ).to(device)\n",
    "\n",
    "        summary_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=150,\n",
    "            min_length=50,\n",
    "            num_beams=4,\n",
    "            do_sample=False,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        summary = tokenizer.decode(\n",
    "            summary_ids[0],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        )\n",
    "\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "\n",
    "def launch_app():\n",
    "    sample_articles = prepare_sample_data()\n",
    "\n",
    "    interface = gr.Interface(\n",
    "        fn=summarize_news,\n",
    "        inputs=gr.Textbox(\n",
    "            lines=12,\n",
    "            label=\"Input News Article\",\n",
    "            placeholder=\"Paste the full text of a news article here...\"\n",
    "        ),\n",
    "        outputs=gr.Textbox(\n",
    "            label=\"Generated Summary\",\n",
    "            interactive=False\n",
    "        ),\n",
    "        title=\"News Summarizer\",\n",
    "        description=\"This app uses facebook/bart-large-xsum for abstractive summarization.\",\n",
    "        examples=[[s] for s in sample_articles],\n",
    "    )\n",
    "\n",
    "    interface.launch(share=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    launch_app()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
